{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9156260,"sourceType":"datasetVersion","datasetId":5531365},{"sourceId":58532,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":49034,"modelId":67289}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# import libraries\nimport random\nimport pandas as pd\nimport numpy as np\nfrom scipy import stats\n\nfrom sklearn.preprocessing import StandardScaler\n\nfrom torch.utils.data import Dataset, DataLoader\nimport imageio.v3 as imageio\nimport albumentations as A\nimport imgaug\nfrom albumentations.pytorch import ToTensorV2\n\nfrom torch import nn\nimport torch\nimport timm\n\nimport torch.optim as optim\nimport torchmetrics\n\nfrom tqdm.notebook import tqdm\ntqdm.pandas()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    imgaug.random.seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_seed(42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load data\ntrain = pd.read_pickle('/kaggle/input/cs480data/cs480train.pkl')\ntest = pd.read_pickle('/kaggle/input/cs480data/cs480test.pkl')\n\nlabels = ['X4_mean', 'X11_mean', 'X18_mean', 'X26_mean', 'X50_mean', 'X3112_mean']\nfeatures = [x for x in (train.columns.values.tolist()) if x not in labels + ['id', 'file_path', 'jpeg_bytes']]\nlower = [0] * 6\nhigher = [0] * 6\nfor idx, c in enumerate(labels):\n    lower[idx] = train[c].quantile(0.005)\n    higher[idx] = train[c].quantile(0.985)\n\nfor idx, c in enumerate(labels):\n    train = train[(train[c] >= lower[idx]) & (train[c] <= higher[idx])]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# transform 1: log-and-scale y-labels\ny = np.zeros_like(train[labels], dtype=np.float32)\nfor idx, label in enumerate(labels):\n    y[:, idx] = np.log10(train[label].values)\n\ny_scaler = StandardScaler()\ny = y_scaler.fit_transform(y)\n\n\n# transform 2: log-and-scale x-features\n# note: for log-transforming x-features, some are negative\n        # we shift those values by the minimum of the feature column\n        # this may pose a problem, i.e. say -5 is minimum of train, but -6 is minimum of test\n        # thus, we will 'clip' the data during the test column transformation\n\nskewness = stats.skew(train[features])\nlog_features = []\nfor skew, feature in zip(skewness, features):\n    if skew > 1: log_features.append(feature)\n\nLOG_TRAIN_FEATURES_MIN_RECOVERY = [0.00] * len(features)  \nx_tab_train = np.zeros_like(train[features], dtype = np.float32)\nfor idx, feature in enumerate(features):\n    v = train[feature].values\n    if feature in log_features:\n        min_val = np.min(v)\n        LOG_TRAIN_FEATURES_MIN_RECOVERY[idx] = np.min(v) if min_val < 0 else 0\n        v = np.log10(v - LOG_TRAIN_FEATURES_MIN_RECOVERY[idx] + 1)\n    x_tab_train[:, idx] = v\n\ntab_scaler = StandardScaler()\nx_tab_train = tab_scaler.fit_transform(x_tab_train)\n\n# transform 3: log-and-scale x-features for test set\nx_tab_test = np.zeros_like(test[features], dtype=np.float32)\nfor idx, feature in enumerate(features):\n    v = test[feature].values\n    if feature in log_features:\n        pre_clipped = v - LOG_TRAIN_FEATURES_MIN_RECOVERY[idx] + 1\n        clipped = np.clip(v, a_min=1e-10, a_max=None) # see here from note in transform 2\n        v = np.log10(clipped)\n    x_tab_test[:, idx] = v\n\nx_tab_test = tab_scaler.fit_transform(x_tab_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 6\nbatch_size = 10\ntotal_steps = len(train) // batch_size * epochs + 1 ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create datasets (mostly borrowed from HdJoJo)\n# image transforms: flip, crop, brightness, compression\nMEAN = [0.485, 0.456, 0.406]\nSTD = [0.229, 0.224, 0.225]\n\n\nTRAIN_IMAGE_TRANSFORMS = A.Compose([\n        A.HorizontalFlip(p=0.5),\n        A.RandomSizedCrop(\n            [112, 128],\n            128, 128, w2h_ratio=1.0, p=0.8),\n        A.Resize(384, 384),\n        A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.3),\n        A.ImageCompression(quality_lower=85, quality_upper=100, p=0.3),\n        A.ToFloat(),\n        A.Normalize(mean=MEAN, std=STD, max_pixel_value=1),\n        ToTensorV2(),\n    ])\n\nTEST_IMAGE_TRANSFORMS = A.Compose([\n        A.Resize(384, 384),\n        A.ToFloat(),\n        A.Normalize(mean=MEAN, std=STD, max_pixel_value=1),\n        ToTensorV2(),\n    ])\n\nclass Dataset(Dataset):\n    def __init__(self, X_jpeg_bytes, X_tab_data, y, image_transforms=None):\n        self.X_jpeg_bytes = X_jpeg_bytes\n        self.tab_data = X_tab_data\n        self.y = y\n        self.image_transforms = image_transforms\n\n    def __len__(self):\n        return len(self.X_jpeg_bytes)\n\n    def __getitem__(self, index):\n        X_image_sample = self.image_transforms(\n            image=imageio.imread(self.X_jpeg_bytes[index]),\n        )['image']\n        X_tabular_sample = self.tab_data[index]\n        y_sample = self.y[index]\n        \n        return X_image_sample, X_tabular_sample, y_sample\n\n\ntrain_dataset = Dataset(\n    train['jpeg_bytes'].values,\n    x_tab_train,\n    y,\n    TRAIN_IMAGE_TRANSFORMS,\n)\n\ntrain_dataloader = DataLoader(\n        train_dataset,\n        batch_size=batch_size,\n        shuffle=True,\n        drop_last=True,\n)\n\ntest_dataset = Dataset(\n    test['jpeg_bytes'].values,\n    x_tab_test,\n    test['id'].values,\n    TEST_IMAGE_TRANSFORMS,\n)\n\ntest_dataloader = DataLoader(\n    test_dataset,\n    batch_size=1,\n    shuffle=False,\n    drop_last=False,\n    num_workers=0\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' # change to cuda/cpu","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model change\ntab_extractor_layer = 512\ntab_feature_rep = 512\nimage_feature_rep = 512\ncomb_l1 = 512\ncomb_l2 = 256\nsecond_layer = True","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define model\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        # tab extractor\n        self.tab_extractor = nn.Sequential(\n            nn.Linear(len(features), tab_extractor_layer),\n            nn.BatchNorm1d(tab_extractor_layer),\n            nn.ReLU(),\n            nn.Linear(tab_extractor_layer, tab_feature_rep)\n        )\n\n        # image extractor\n        self.pre_trained = timm.create_model('swin_large_patch4_window12_384.ms_in22k_ft_in1k', num_classes=len(labels), pretrained=False)\n        self.pre_trained.load_state_dict(torch.load('/kaggle/input/swin-transformer-v1-planttraits2024-finetuned/pytorch/log3-noval-8epoch/1/model_08.pth'))\n        for p in self.pre_trained.parameters(): p.requires_grad = False # freeze\n        self.pre_trained.head = nn.Identity()\n        self.image_extractor = nn.Sequential(nn.AdaptiveAvgPool2d(1), nn.Flatten(), nn.Linear(self.pre_trained.num_features, image_feature_rep))\n\n        # combination layers\n        if second_layer:\n            self.concat_nn = nn.Sequential(\n                nn.Linear(tab_feature_rep + image_feature_rep, comb_l1),\n                nn.BatchNorm1d(comb_l1),\n                nn.ReLU(),\n                nn.Linear(comb_l1, comb_l2),\n                nn.BatchNorm1d(comb_l2),\n                nn.ReLU(),\n                nn.Linear(comb_l2, len(labels))\n            )\n        else:\n            self.concat_nn = nn.Sequential(\n                nn.Linear(tab_feature_rep + image_feature_rep, comb_l1),\n                nn.BatchNorm1d(comb_l1),\n                nn.ReLU(),\n                nn.Linear(comb_l1, len(labels))\n            )\n        \n    def forward(self, image, tabular):\n        # extract from Image\n        image_features = self.image_extractor(self.pre_trained(image).permute(0,3,1,2))\n        # extract from Tabular\n        tabular_features = self.tab_extractor(tabular)\n        # fusion\n        combo_features = torch.cat([image_features, tabular_features], dim=1)\n        # combination\n        output = self.concat_nn(combo_features)\n        return output\n\nmodel = Model()\nmodel = model.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr = 1e-4\nweight_decay = 1e-2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define scheduler/metrics\nclass AverageMeter(object):\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val):\n        self.sum += val.sum()\n        self.count += val.numel()\n        self.avg = self.sum / self.count\n\nMAE = torchmetrics.regression.MeanAbsoluteError().to(device)\nR2 = torchmetrics.regression.R2Score(num_outputs=len(labels), multioutput='uniform_average').to(device)\nLOSS = AverageMeter()\n\nloss_fn = nn.SmoothL1Loss()\n\ndef get_lr_scheduler(optimizer, lr_max):\n    return torch.optim.lr_scheduler.OneCycleLR(\n        optimizer=optimizer,\n        max_lr=lr_max,\n        total_steps=total_steps,\n        pct_start=0.1,\n        anneal_strategy='cos',\n        div_factor=1e1,\n        final_div_factor=1e1,\n    )\n\noptimizer = torch.optim.AdamW(params=model.parameters(),lr=lr, weight_decay=weight_decay)\nscheduler = get_lr_scheduler(optimizer, lr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training\ntracker = np.zeros((epochs, len(train) // batch_size), dtype=float)\nfor epoch in range(epochs):\n    model.train()\n    MAE.reset()\n    R2.reset()\n    LOSS.reset()\n\n    for step, (image, tab, y) in enumerate(train_dataloader):\n        image = image.to(device)\n        tab = tab.to(device)\n        y = y.to(device)\n        model = model.to(device)\n\n        y_pred = model(image, tab)\n\n        loss = loss_fn(y, y_pred)\n        loss.backward()\n\n        optimizer.step()\n        optimizer.zero_grad()\n\n        scheduler.step()\n        \n        LOSS.update(loss)\n        MAE.update(y_pred, y)\n        R2.update(y_pred, y)\n\n        tracker[epoch, step] = loss\n\n        if (step + 1) == len(train) // batch_size:\n            print(str(epoch + 1))\n            print(str(LOSS.avg))\n            print(str(MAE.compute().item()))\n            print(str(R2.compute().item()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# save model\ntorch.save(model.to('cpu').state_dict(), 'model.pth')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# evaluate model\nsubmission_rows = []\nmodel.to(device)\nmodel.eval()\nfor image, tab, id in tqdm(test_dataloader):\n    with torch.no_grad():\n        y_pred = model(image.to(device), tab.to(device)).detach().cpu().numpy()\n\n    y_pred = y_scaler.inverse_transform(y_pred).squeeze()\n    row = {'id': int(id)}\n\n    for k, v in zip(labels, y_pred):\n        row[k.replace('_mean', '')] = 10 ** v\n    \n    submission_rows.append(row)\n\nsubmission_df = pd.DataFrame(submission_rows)\nsubmission_df.to_csv('20892920_huh.csv', index=False)\nprint('done')","metadata":{},"execution_count":null,"outputs":[]}]}