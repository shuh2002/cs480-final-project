{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.13 (you have 1.4.12). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import imageio.v3 as imageio\n",
    "import albumentations as A\n",
    "import imgaug\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from torch import nn\n",
    "import torch\n",
    "import timm\n",
    "\n",
    "import torch.optim as optim\n",
    "import torchmetrics\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    imgaug.random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set a specific seed for reproducibility\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train = pd.read_pickle('./data/cs480train.pkl')\n",
    "test = pd.read_pickle('./data/cs480test.pkl')\n",
    "\n",
    "labels = ['X4_mean', 'X11_mean', 'X18_mean', 'X26_mean', 'X50_mean', 'X3112_mean']\n",
    "features = [x for x in (train.columns.values.tolist()) if x not in labels + ['id', 'file_path', 'jpeg_bytes']]\n",
    "lower = [0] * 6\n",
    "higher = [0] * 6\n",
    "for idx, c in enumerate(labels):\n",
    "    lower[idx] = train[c].quantile(0.005)\n",
    "    higher[idx] = train[c].quantile(0.985)\n",
    "\n",
    "for idx, c in enumerate(labels):\n",
    "    train = train[(train[c] >= lower[idx] and (train[c] <= higher[idx]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform 1: log-and-scale y-labels\n",
    "y = np.zeros_like(train[labels], dtype=np.float32)\n",
    "for idx, label in enumerate(labels):\n",
    "    y[:, idx] = np.log10(train[label].values)\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y = y_scaler.fit_transform(y)\n",
    "\n",
    "\n",
    "# transform 2: log-and-scale x-features\n",
    "# note: for log-transforming x-features, some are negative\n",
    "        # we shift those values by the minimum of the feature column\n",
    "        # this may pose a problem, i.e. say -5 is minimum of train, but -6 is minimum of test\n",
    "        # thus, we will 'clip' the data during the test column transformation\n",
    "\n",
    "skewness = stats.skew(train[features])\n",
    "log_features = []\n",
    "for skew, feature in zip(skewness, features):\n",
    "    if skew > 1: log_features.append(feature)\n",
    "\n",
    "LOG_TRAIN_FEATURES_MIN_RECOVERY = [0.00] * len(features)  \n",
    "x_tab_train = np.zeros_like(train[features], dtype = np.float32)\n",
    "for idx, feature in enumerate(features):\n",
    "    v = train[feature].values\n",
    "    if feature in log_features:\n",
    "        min_val = np.min(v)\n",
    "        LOG_TRAIN_FEATURES_MIN_RECOVERY[idx] = np.min(v) if min_val < 0 else 0\n",
    "        v = np.log10(v - LOG_TRAIN_FEATURES_MIN_RECOVERY[idx] + 1)\n",
    "    x_tab_train[:, idx] = v\n",
    "\n",
    "tab_scaler = StandardScaler()\n",
    "x_tab_train = tab_scaler.fit_transform(x_tab_train)\n",
    "\n",
    "# transform 3: log-and-scale x-features for test set\n",
    "x_tab_test = np.zeros_like(test[features], dtype=np.float32)\n",
    "for idx, feature in enumerate(features):\n",
    "    v = test[feature].values\n",
    "    if feature in log_features:\n",
    "        pre_clipped = v - LOG_TRAIN_FEATURES_MIN_RECOVERY[idx] + 1\n",
    "        clipped = np.clip(v, a_min=1e-10, a_max=None) # see here from note in transform 2\n",
    "        v = np.log10(clipped)\n",
    "    x_tab_test[:, idx] = v\n",
    "\n",
    "x_tab_test = tab_scaler.fit_transform(x_tab_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 6\n",
    "batch_size = 10\n",
    "total_steps = len(train) // batch_size * epochs + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create datasets (mostly borrowed from HdJoJo)\n",
    "# image transforms: flip, crop, brightness, compression\n",
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "\n",
    "TRAIN_IMAGE_TRANSFORMS = A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.RandomSizedCrop(\n",
    "            [112, 128],\n",
    "            128, 128, w2h_ratio=1.0, p=0.8),\n",
    "        A.Resize(384, 384),\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.3),\n",
    "        A.ImageCompression(quality_lower=85, quality_upper=100, p=0.3),\n",
    "        A.ToFloat(),\n",
    "        A.Normalize(mean=MEAN, std=STD, max_pixel_value=1),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "TEST_IMAGE_TRANSFORMS = A.Compose([\n",
    "        A.Resize(384, 384),\n",
    "        A.ToFloat(),\n",
    "        A.Normalize(mean=MEAN, std=STD, max_pixel_value=1),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, X_jpeg_bytes, X_tab_data, y, image_transforms=None):\n",
    "        self.X_jpeg_bytes = X_jpeg_bytes\n",
    "        self.tab_data = X_tab_data\n",
    "        self.y = y\n",
    "        self.image_transforms = image_transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_jpeg_bytes)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X_image_sample = self.image_transforms(\n",
    "            image=imageio.imread(self.X_jpeg_bytes[index]),\n",
    "        )['image']\n",
    "        X_tabular_sample = self.tab_data[index]\n",
    "        y_sample = self.y[index]\n",
    "        \n",
    "        return X_image_sample, X_tabular_sample, y_sample\n",
    "\n",
    "\n",
    "train_dataset = Dataset(\n",
    "    train['jpeg_bytes'].values,\n",
    "    x_tab_train,\n",
    "    y,\n",
    "    TRAIN_IMAGE_TRANSFORMS,\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    ")\n",
    "\n",
    "test_dataset = Dataset(\n",
    "    test['jpeg_bytes'].values,\n",
    "    x_tab_test,\n",
    "    test['id'].values,\n",
    "    TEST_IMAGE_TRANSFORMS,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu' # change to cuda if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model change\n",
    "tab_extractor_layer = 512\n",
    "tab_feature_rep = 512\n",
    "image_feature_rep = 512\n",
    "comb_l1 = 1024\n",
    "comb_l2 = 256\n",
    "second_layer = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        # tab extractor\n",
    "        self.tab_extractor = nn.Sequential(\n",
    "            nn.Linear(len(features), tab_extractor_layer),\n",
    "            nn.BatchNorm1d(tab_extractor_layer),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(tab_extractor_layer, tab_feature_rep)\n",
    "        )\n",
    "\n",
    "        # image extractor\n",
    "        self.pre_trained = timm.create_model('swin_ltorch.manual_seed(0)arge_patch4_window12_384.ms_in22k_ft_in1k', num_classes=len(labels), pretrained=False)\n",
    "        self.pre_trained.load_state_dict(torch.load('./model/model.pth'))\n",
    "        for p in self.pre_trained.parameters(): p.requires_grad = False # freeze\n",
    "        self.pre_trained.head = nn.Identity()\n",
    "        self.image_extractor = nn.Sequential(nn.AdaptiveAvgPool2d(1), nn.Flatten(), nn.Linear(self.pre_trained.num_features), image_feature_rep)\n",
    "\n",
    "        # combination layers\n",
    "        if second_layer:\n",
    "            self.concat_nn = nn.Sequential(\n",
    "                nn.Linear(tab_feature_rep + image_feature_rep, comb_l1),\n",
    "                nn.BatchNorm1d(comb_l1),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(comb_l1, comb_l2),\n",
    "                nn.BatchNorm1d(comb_l2),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(comb_l2, len(labels))\n",
    "            )\n",
    "        else:\n",
    "            self.concat_nn = nn.Sequential(\n",
    "                nn.Linear(tab_feature_rep + image_feature_rep, comb_l1),\n",
    "                nn.BatchNorm1d(comb_l1),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(comb_l1, len(labels))\n",
    "            )\n",
    "        \n",
    "    def forward(self, image, tabular):\n",
    "        # extract from Image\n",
    "        image_features = self.image_extractor(self.pre_trained(image).permute(0,3,1,2))\n",
    "        # extract from Tabular\n",
    "        tabular_features = self.tab_extractor(tabular)\n",
    "        # fusion\n",
    "        combo_features = torch.cat([image_features, tabular_features], dim=1)\n",
    "        # combination\n",
    "        output = self.concat_nn(combo_features)\n",
    "        return output\n",
    "\n",
    "model = Model().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "weight_decay = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define scheduler/metrics\n",
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val):\n",
    "        self.sum += val.sum()\n",
    "        self.count += val.numel()\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "MAE = torchmetrics.regression.MeanAbsoluteError().to(device)\n",
    "R2 = torchmetrics.regression.R2Score(num_outputs=len(labels), multioutput='uniform_average').to(device)\n",
    "LOSS = AverageMeter()\n",
    "\n",
    "loss_fn = nn.SmoothL1Loss()\n",
    "\n",
    "def get_lr_scheduler(optimizer, lr_max):\n",
    "    return torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer=optimizer,\n",
    "        max_lr=lr_max\n",
    "        total_steps=CONFIG.N_STEPS,\n",
    "        pct_start=0.1,\n",
    "        anneal_strategy='cos',\n",
    "        div_factor=1e1,\n",
    "        final_div_factor=1e1,\n",
    "    )\n",
    "\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(),lr=lr, weight_decay=weight_decay)\n",
    "scheduler = get_lr_scheduler(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "tracker = np.zeros((epochs, len(train) // batch_size), dtype=float)\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    MAE.reset()\n",
    "    R2.reset()\n",
    "    LOSS.reset()\n",
    "\n",
    "    for step, (image, tab, y) in enumerate(train_dataloader):\n",
    "        image = image.to(device)\n",
    "        tab = tab.to(device)\n",
    "        y = y.to(device)\n",
    "        model = model.to(device)\n",
    "\n",
    "        y_pred = model(image, tab)\n",
    "\n",
    "        loss = loss_fn(y, y_pred)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        MAE.update(y_pred, y)\n",
    "        R2.update(y_pred, y)\n",
    "\n",
    "        tracker[epoch, step] = loss\n",
    "\n",
    "        if (step + 1) == len(train) // batch_size:\n",
    "            print(str(epoch + 1))\n",
    "            print(str(LOSS.avg))\n",
    "            print(str(MAE.compute().item()))\n",
    "            print(str(R2.compute.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save(model.to('cpu').state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "submission_rows = []\n",
    "model.to(device)\n",
    "model.eval()\n",
    "for image, tab, id in tqdm(test_dataloader):\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(image.to(device), tab.to(device)).detach().cpu().numpy()\n",
    "\n",
    "    y_pred = y_scaler.inverse_transform(y_pred).squeeze()\n",
    "    row = {'id': int(id)}\n",
    "\n",
    "    for k, v in zip(labels, y_pred):\n",
    "        row[k.replace('_mean', '')] = 10 ** v\n",
    "    \n",
    "    submission_rows.append(row)\n",
    "\n",
    "submission_df = pd.DataFrame(submission_rows)\n",
    "submission_df.to_csv('./20892920_huh.csv', index=False)\n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
